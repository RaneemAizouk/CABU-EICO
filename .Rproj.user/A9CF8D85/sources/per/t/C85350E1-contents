# Set the working directory to Desktop/Rfiles
setwd("/Users/raizouk/Desktop/R files")

# Load packages, checks if the "pacman" package is installed. If not, it installs the package and loads it.
if (!require(pacman)) {
  install.packages("pacman")
  library(pacman)
}

p_load(viridis, adaptivetau)
if (!require(msm)){
install.packages("msm")
library(msm)
}
p_load(viridis, adaptivetau)
if (!require(msm)){
  install.packages("tidyverse")
  library(msm)
}

# Clear workspace, remove all objects from the current environment.
rm(list = ls())
# 1) Simulate Disease Spread using  the Gillespie algorithm.
# Source model functions, sources (loads) functions from the file named "between_host_invu_fn_raneem.R"
source("./between_host_invu_fn_raneem3.R")

# Initialize an empty list to store results
results_list <- list()
# Add household identifier column to all_data
all_data <- data.frame(t = numeric(), S = numeric(), I = numeric(), HouseID = integer())


# Simulation Params
# a sequence of time points from 0 to 14 with a step of 1.
tvec <- seq(0, 14, 1)
tmax<- max(tvec)
lambda1 = 0.2
lambda2 = 0.3
rho = 0.2

# Color palette for plotting
cols <- viridis(3)
# results_list and  result are the lists for the general simulations.
# Stochastic simulation
# we consider the simulations over the clusters and houses. 
# Repeat simulations for (n.sims) times
n.sims <- 10
n.clusters <- 22
houses_per_cluster <- 12
for (sim in 1:n.sims) {
  # Run simulations for each cluster
  for (cluster in 1:n.clusters) {
    # Run simulations for each house in the cluster
    for (house in 1:houses_per_cluster) {
      # Call the gillespe function
      N <- sample(1:5, 1)  # Random number of individuals in the house with maximum 5 individuals per house.
      S1 <- sample(0:N, 1)  # Random number of susceptible individuals in the house
      I1 <- N - S1  # Ensure that S0 + I0 equals N
      state.orig <- c(I = I1, S = S1)
      result <-  gillespe (lambda1, lambda2 , rho,S1,I1,tmax,N)
      # Calculate HouseID
      HouseID <- rep((cluster - 1) * houses_per_cluster + house, length(result$t))
      
        # Combine results and identifiers
        result <- cbind(result, HouseID)
        # Store the result in the list
        results_list[[length(results_list) + 1]] <- result
      
      }
    }
  
}
print(result)
# 2) Find the mean which include a) Rounding the time points using the floor function. This step acknowledges that the mean cannot be calculated for continuous time points, so rounding them down to the nearest whole number provides discrete time points for aggregation
# b) put them in a new list with the corresponding S and I values. c) find the mean 
# To find the mean, we took the floor function on the time values to round them down to the nearest whole number and store the corresponding values for S and I in a data frame.
# The resulting data frame (approx_list) provides a summarized view of the simulation results at discrete time points, making it easier to calculate and visualize the mean behavior over time.
# approx_list: is the list for the aproximated values to draw the mean.
approx_list <- list() # create an empty list()
for (item in results_list){
  approx_list[[length(approx_list)+1]] <- data.frame(t=floor(item$t), S=item$S, I=item$I)
}

# we will have repeated time values so we wanted to ensures to aggregate or summarise data at each unique time point. why we use group_by(t)
grouped_approx_list <- do.call(rbind, approx_list) %>%
  group_by(t) %>%
  add_count(name="group_count") %>%
  summarize(S = sum(S), I = sum(I), group_count=unique(group_count))
# to combine the data frames in the list approx_list into a single data frame and then perform further operations using the %>% (pipe) operator.
out.mean <- do.call(rbind,approx_list) %>%
  # to combine similar time values. 
  group_by(t) %>%
  #group_count: provides the count of observations (group_count) for each unique time point in the data.
  add_count(name="group_count") %>%
  summarize(mean_S = sum(S)/ n(), mean_I = sum(I)/n(), group_count=unique(group_count))

print(out.mean)


#SHALL WE APROOXIMATE THE MEANS TO UNIQIE TIMES POINTS OR LEAVE IT AS DECIMALS ?
# Plot output

names(out.mean) <- c("time", "S", "I")
alphaval <- 0.3

par(mfrow=c(1,1))
plot(NULL,
     las=1,xaxs="i",yaxs="i",ylim=c(0,6),bty="n",xlim=range(tvec),
     xlab="time",ylab="Frequency")
# Plot legend
legend("topleft", bty="n", col=cols[1:2], legend=c("Susceptible", "Infected"), lwd=3)


# Plot individual simulations
for (ii in 1:n.sims) {
  lines(results_list[[ii]]$t, results_list[[ii]]$S, col=adjustcolor(cols[1], alphaval))
  lines(results_list[[ii]]$t, results_list[[ii]]$I, col=adjustcolor(cols[2], alphaval))
}

# Corrected lines for plotting the mean
lines(out.mean[["time"]],out.mean[["S"]],col=adjustcolor(cols[1]),lwd=3)
lines(out.mean[["time"]],out.mean[["I"]],col=adjustcolor(cols[2]),lwd=3)

# 3) Drewing samples by choosing the nearst time point to the required time points c(3,6,9,12)

# Assuming results_list is your list of results
desired_time_points <- c(3, 6, 9, 12)

nearest_times_list <- lapply(results_list, function(item) {
  sapply(desired_time_points, function(time) {
    closest_points <- item$t[item$t <= time]
    if (length(closest_points) > 0) {
      return(tail(closest_points, 1))
    } else {
      return(NA)
    }
  })
})

# Create Time_list
Time_list <- list()

for (i in seq_along(nearest_times_list)) {
  time_points <- unique(na.omit(unlist(nearest_times_list[[i]])))
  #na.omit.:Removes NA values 
  if (length(time_points) > 0) {
    S_values <- results_list[[i]]$S[results_list[[i]]$t %in% time_points]
    I_values <- results_list[[i]]$I[results_list[[i]]$t %in% time_points]
    HouseID_values <- results_list[[i]]$HouseID[results_list[[i]]$t %in% time_points]
    common_data <- data.frame(t = time_points, S = S_values, I = I_values,HouseID = HouseID_values)
    Time_list[[i]] <- common_data
    
  }
}

# Combine data from Time_list into a single data frame
all_data <- do.call(rbind, Time_list)

# Order the data by subject (HouseID) and time (t)
all_data <- all_data %>% arrange(HouseID, t)

# Print the unique time points for each simulation
print(all_data)

library(dplyr)

library(tidyverse) 
library(msm)
# Assuming 'all_data' is the data frame
aggregated_data <- all_data %>%
  group_by( HouseID,t) %>%
  
  mutate(PTNUM = row_number()) %>%
  summarize(S = sum(S), I = sum(I))

# Assuming 'all_data' is your data frame
long_data <- aggregated_data %>% 
  pivot_longer(cols = c("S", "I"), names_to = "state", values_to = "count") %>%
  mutate(state_numeric = ifelse(state == "S", 1, 2),  # Convert "S" to 1 and "I" to 2
         PTNUM = rep(1:(n() / 2), each = 2)) %>%  # Create an 'id' column
  arrange(t)  # Arrange the data by time

# Ensure 'state' is a factor with levels 1 and 2
long_data$state_numeric <- factor(long_data$state_numeric, levels = c("1", "2"))

# Display the reshaped data
print(long_data)









# Run a basic Markov model without considering clusters and houses
Q <- matrix(c(-0.5, 0.5, 0.2, -0.2), nrow = 2, ncol = 2, byrow = TRUE)

result <- msm(formula = state_numeric ~ t,
              subject = cbind(PTNUM, long_data$HouseID),  # Include HouseID in subject
              data = long_data,
              qmatrix = Q,
              gen.inits = TRUE)


# Print the model result
print(result)


# Example
nrow_all_data <- 58
HouseID <- rep(1:ceiling(nrow_all_data / 12), each = 12, length.out = nrow_all_data)

# Display the result
print(HouseID)








print(str(long_data) )
# Use aggregated_data if needed
#aggregated_data <- long_data %>%
#  group_by(id, t) %>%
#  summarize(state_numeric = first(state_numeric))



library(msm)

# Assuming 'long_data' is your data frame
# A simple summary of the data is a count of  the number of transitions between states. 
#the rows represent the "from" states, the columns represent the "to" states, and the values in the table represent the counts or frequencies of transitions from one state to another.
result1 <- statetable.msm(state = long_data$state_numeric, data = long_data)

# Print the result
print(result1)
#some idea of the time scale.
summary(long_data$t)


# Create Q matrix
Q <- matrix(c(-0.5, 0.5, 0.2, -0.2), nrow = 2, ncol = 2, byrow = TRUE)
print(Q)

# Assuming 'long_data' is your data frame and 'Q' is your transition rate matrix
result <- msm(formula = state_numeric ~ t ,
              subject = PTNUM,  
              data = long_data, 
              qmatrix = Q,
              gen.inits = TRUE)


# Print the modified Time_list
print(Time_list)



# NNNNEEEWWWWW PAAARRTTT
# Assuming Time_list is your list of results
desired_time_points <- c(0, 3, 6, 9, 12)  # Specify the desired time points or intervals
#rounded_times_list is the sample (Time_list)approximation
# Approximate time points to the nearest upper value from the set of desired time points(0,3,6,9,12)
rounded_times_list <- lapply(Time_list, function(item) {
  item$t <- sapply(item$t, function(time) min(desired_time_points[desired_time_points >= time]))
  return(item)
})

# Create a data frame for the rounded time points and sum of S and I values
rounded_data <- do.call(rbind, lapply(rounded_times_list, function(item) {
  data.frame(t = item$t, S = sum(item$S), I = sum(item$I))
}))

# Group the sample by rounded time points and summarize
grouped_rounded_data <- rounded_data %>%
  group_by(t) %>%
  summarize(S = sum(S), I = sum(I), count = n())

# Print the rounded_data: the data from the time list with time points approximated to the nearest top desired time point.
print(rounded_data)

# Print the grouped_rounded_data:the data from the rounded_data with time points grouped at the desired time point to avoid repitition.
print(grouped_rounded_data)

# Assuming grouped_rounded_data is your data frame
#write.csv(grouped_rounded_data, "~/Desktop/R files/Data.csv", row.names = FALSE)





# # Open a graphics device (use the appropriate one for your system)
# # windows()  # Uncomment this line if you are using Windows
# # X11()      # Uncomment this line if you are using Linux/Mac
# names(Time_list) <- c("time", "S", "I")
# # Set alpha value for transparency
# alphaval <- 0.3
# par(mfrow = c(1, 1))
# # Set up the initial plot
# plot(NULL, las = 1, xaxs = "i", yaxs = "i", ylim = c(0, 6), bty = "n", xlim = range(tvec), xlab = "time", ylab = "Frequency")
# # Plot legend
# legend("topleft", bty = "n", col = c("blue", "red"), legend = c("Susceptible (S)", "Infected (I)"), lwd = 3)
# 
# # Plot simulations from Time_list
# for (i in seq_along(Time_list)) {
#   current_data <- Time_list[[i]]
#   
#   # Plot 'S' and 'I' values against time
#   lines(current_data$t, current_data$S, col = adjustcolor("blue", alphaval))
#   lines(current_data$t, current_data$I, col = adjustcolor("red", alphaval))
# }
# #introduction for likelihood_function

# Assuming 'Time_list' contains the time-series data for each simulation
# Note: You may need to modify this based on the actual structure of your data
# Each element of 'Time_list' should be a data frame with columns 't', 'S', and 'I'
# Convert the matrix to a data frame
# Assuming your_data is your data frame
# Assuming grouped_rounded_data is your data frame

# Combine data from Time_list into a single data frame
# Concatenate data frames in grouped_rounded_data into a single data frame


all_data1 <- do.call(rbind, grouped_rounded_data)

print(all_data1)

























# 1) define the transition matrix.
# Define transition rate functions
# Parameters
lambda1 <- 0.2 # External infection rate
lambda2 <- 0.3
rho <- 0.2


transition_S_to_I <- function(S, I) (lambda1 + lambda2 * I) * S
transition_I_to_S <- function(S, I) rho * I * S

# Q Matrix for SIS model
Q <- matrix(0, nrow = 2, ncol = 2)
rownames(Q) <- colnames(Q) <- c("S", "I")

# Set numerical values in the Q matrix
Q[1, 2] <- transition_S_to_I(S, I)  # Transition from S1 to I1
Q[2, 1] <- transition_I_to_S(S, I)  # Transition from I1 to S1

# Ensure rows sum to zero
Q <- Q - diag(rowSums(Q))

# Print the Q matrix
print(Q)


# Assuming 'Time_list' contains the time-series data for each simulation
# Note: You may need to modify this based on the actual structure of your data
# Each element of 'Time_list' should be a data frame with columns 't', 'S', and 'I'

# Combine data from Time_list into a single data frame
all_data <- do.call(rbind, Time_list)

# Create a 'long' format suitable for msm
msm_data <- data.frame(
  id = rep(1:n.sims, each = length(Time_list[[1]]$t)),
  time = rep(Time_list[[1]]$t, n.sims),
  state = rep(c("S", "I"), each = length(Time_list[[1]]$t) * n.sims),
  value = c(all_data$S, all_data$I)
)

# Fit a multi-state model
# Note: You need to specify the transition intensities (Q matrix) based on your model
# This is a simplified example, and you should adapt it to your specific model.

# Convert 'S' and 'I' to numeric values
msm_data$state_numeric <- as.numeric(factor(msm_data$state, levels = c("S", "I")))

# Fit a multi-state model
model <- msm(state_numeric ~ time, subject = id, data = msm_data, qmatrix = matrix(c(-0.1, 0.1, 0.1, -0.1), 2, 2))

# Summary of the fitted model
summary(model)

